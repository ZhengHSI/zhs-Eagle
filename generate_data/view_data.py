# This script is used to view the data generated by the generate_data.py script.
# It will print the data in the console with colors based on the loss mask.

import argparse
import torch
from transformers import AutoTokenizer

# ANSI color codes
RED = "\033[91m"
GREEN = "\033[92m"
RESET = "\033[0m"


def main():
    parser = argparse.ArgumentParser(description="View data")
    parser.add_argument("--data-path", type=str, default="/workdir/datasets/ultrachat_200k/1/data_0.ckpt")
    parser.add_argument(
        "--tokenizer", type=str, default="/workdir/huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
    )
    args = parser.parse_args()

    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer)

    data = torch.load(args.data_path)

    input_ids = data["input_ids"]
    print(f"Loss mask sum: {data['loss_mask'].sum()}")
    loss_mask = data["loss_mask"].tolist()

    current_mask = input_ids[0]
    current_ids = []

    for i in range(len(input_ids)):
        if current_mask == loss_mask[i]:
            current_ids.append(input_ids[i])
        else:
            decoded_text = tokenizer.decode(current_ids, skip_special_tokens=False)
            if current_mask == 0:
                print(f"{RED}{decoded_text}{RESET}", end="")
            else:
                print(f"{GREEN}{decoded_text}{RESET}", end="")
            current_ids = [input_ids[i]]
            current_mask = loss_mask[i]

    print(f"{GREEN}{tokenizer.decode(current_ids, skip_special_tokens=False)}{RESET}")

    print()
    print(f"input_ids shape: {data['input_ids'].shape}")
    print(f"loss_mask shape: {data['loss_mask'].shape}")
    print(f"hidden_state shape: {data['hidden_state'].shape}")


if __name__ == "__main__":
    main()
